"""
Service de g√©n√©ration d'images pour les histoires interactives

Ce service g√®re la g√©n√©ration d'images illustrant les sc√®nes narratives
en utilisant des mod√®les de diffusion (Stable Diffusion). Il est responsable de :
- Chargement et gestion du mod√®le de g√©n√©ration d'images
- Construction de prompts visuels √† partir du contexte narratif
- G√©n√©ration d'images coh√©rentes avec le style et le genre
- Optimisation et sauvegarde des images g√©n√©r√©es
- Gestion des erreurs et modes d√©grad√©s

Architecture :
- Singleton pattern pour √©viter de recharger le mod√®le
- Cache des images g√©n√©r√©es pour √©viter la reg√©n√©ration
- Support de diff√©rents backends (local, API externe)
"""

import asyncio
import time
import os
import hashlib
from typing import Dict, Optional, Tuple
from datetime import datetime
from PIL import Image
import io
import base64

try:
    import torch
    from diffusers import AutoPipelineForText2Image
    DIFFUSERS_AVAILABLE = True
except ImportError:
    DIFFUSERS_AVAILABLE = False
    print("Warning: diffusers not available. Using mock image generation.")

from app.models.schemas import Story, Scene, StoryGenre
from app.config import settings


class ImageGenerationService:
    """
    Service de g√©n√©ration d'images pour les sc√®nes narratives
    
    Ce service encapsule toute la logique de g√©n√©ration d'images :
    - Gestion du mod√®le Stable Diffusion
    - Construction de prompts visuels contextuels
    - G√©n√©ration et optimisation d'images
    - Cache et sauvegarde des r√©sultats
    """
    
    _instance = None
    _pipeline = None
    _model_loaded = False
    
    def __new__(cls):
        """
        Impl√©mentation du pattern Singleton
        √âvite de recharger le mod√®le co√ªteux √† chaque instanciation
        """
        if cls._instance is None:
            cls._instance = super(ImageGenerationService, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        """
        Initialise le service de g√©n√©ration d'images
        Ne charge le mod√®le que si ce n'est pas d√©j√† fait (Singleton)
        """
        if not hasattr(self, '_initialized'):
            self._initialized = True
            
            # D√©tection automatique du device
            self.device = self._detect_device(settings.IMAGE_MODEL_DEVICE)
            self.model_name = settings.IMAGE_MODEL_NAME
            self.images_path = settings.IMAGES_PATH
            
            print(f"üé® Service d'images configur√© - Device: {self.device}, Mod√®le: {self.model_name}")
            
            # Assurer que le r√©pertoire d'images existe
            os.makedirs(self.images_path, exist_ok=True)
            
            # Param√®tres de g√©n√©ration par d√©faut
            self.generation_params = {
                "width": 512,  # R√©solution native de SDXL-Turbo
                "height": 512,
                "num_inference_steps": 2,  # 2-4 steps optimal pour SDXL-Turbo
                "guidance_scale": 0.0,  # Pas de guidance pour Turbo
                "num_images_per_prompt": 1,
                "generator": None  # Sera d√©fini avec une seed
            }
            
            # Cache des images g√©n√©r√©es (√©vite reg√©n√©ration)
            self._image_cache = {}
            self._cache_max_size = 50
            
            # Templates de style par genre
            self._genre_styles = self._initialize_genre_styles()
            
            # Prompts n√©gatifs par d√©faut
            self.negative_prompts = {
                "default": "blurry, low quality, distorted, deformed, text, watermark, signature, username, logo",
                "realistic": "cartoon, anime, painting, drawing, illustration, comic",
                "artistic": "photograph, photorealistic, realistic"
            }
    
    def _detect_device(self, device_setting: str) -> str:
        """
        D√©tecte automatiquement le meilleur device disponible
        
        Args:
            device_setting: Configuration du device ('auto', 'cuda', 'cpu')
            
        Returns:
            str: Device √† utiliser ('cuda' ou 'cpu')
        """
        if device_setting.lower() == "auto":
            if DIFFUSERS_AVAILABLE and torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                gpu_name = torch.cuda.get_device_name(0) if gpu_count > 0 else "Unknown"
                print(f"üéÆ CUDA d√©tect√© pour les images! GPU disponibles: {gpu_count}, Nom: {gpu_name}")
                return "cuda"
            else:
                print("üíª CUDA non disponible pour les images, utilisation du CPU")
                return "cpu"
        else:
            return device_setting.lower()
    
    async def initialize_model(self) -> bool:
        """
        Charge le mod√®le de g√©n√©ration d'images de mani√®re asynchrone
        
        Returns:
            bool: True si le mod√®le est charg√© avec succ√®s
        """
        if self._model_loaded:
            return True
        
        if not DIFFUSERS_AVAILABLE:
            print("Diffusers non disponible. Mode simulation activ√©.")
            self._model_loaded = True
            return True
        
        try:
            print(f"Chargement du mod√®le d'images {self.model_name}...")
            start_time = time.time()
            
            # D√©sactiver temporairement accelerate pour √©viter les erreurs offload_state_dict
            import os
            old_no_init_check = os.environ.get("TRANSFORMERS_NO_INIT_CHECK", None)
            os.environ["TRANSFORMERS_NO_INIT_CHECK"] = "1"
            
            # Configuration EXACTE selon la documentation officielle SDXL-Turbo
            self._pipeline = AutoPipelineForText2Image.from_pretrained(
                self.model_name,
                torch_dtype=torch.float16,
                variant="fp16"
            )
            
            # Restaurer l'environnement
            if old_no_init_check is None:
                os.environ.pop("TRANSFORMERS_NO_INIT_CHECK", None)
            else:
                os.environ["TRANSFORMERS_NO_INIT_CHECK"] = old_no_init_check
            
            # D√©placement sur le device appropri√©
            self._pipeline = self._pipeline.to(self.device)
            
            # FIX OFFICIEL pour SDXL-Turbo: enable_vae_tiling et enable_vae_slicing
            # Ces m√©thodes permettent de g√©rer les probl√®mes de NaN sans changer le dtype
            if self.device == "cuda":
                try:
                    # Enable VAE tiling pour g√©rer les grandes images
                    self._pipeline.enable_vae_tiling()
                    print("‚úÖ VAE tiling activ√©")
                except Exception as e:
                    print(f"VAE tiling non disponible: {e}")
                
                try:
                    # Enable VAE slicing pour √©conomiser la m√©moire
                    self._pipeline.enable_vae_slicing()
                    print("‚úÖ VAE slicing activ√©")
                except Exception as e:
                    print(f"VAE slicing non disponible: {e}")
            
            # Optimisations m√©moire si CUDA
            if self.device == "cuda":
                try:
                    # Activer attention slicing pour √©conomiser la m√©moire
                    self._pipeline.enable_attention_slicing()
                    print("‚úÖ Attention slicing activ√©")
                except Exception as optimization_error:
                    print(f"Avertissement: Optimisations m√©moire non disponibles: {optimization_error}")
            
            load_time = time.time() - start_time
            print(f"Mod√®le d'images charg√© avec succ√®s en {load_time:.2f}s")
            
            self._model_loaded = True
            return True
            
        except Exception as e:
            print(f"Erreur lors du chargement du mod√®le d'images: {str(e)}")
            print("Basculement vers le mode simulation d'images...")
            self._model_loaded = True  # Mode d√©grad√©
            return False
    
    async def generate_scene_image(self, story: Story, scene: Scene, style_override: Optional[str] = None) -> Optional[str]:
        """
        G√©n√®re une image pour une sc√®ne donn√©e
        
        Args:
            story: Histoire associ√©e
            scene: Sc√®ne √† illustrer
            style_override: Style visuel optionnel pour surcharger le genre
            
        Returns:
            Optional[str]: URL/path de l'image g√©n√©r√©e ou None si erreur
        """
        try:
            # Construction du prompt visuel
            image_prompt = self._build_image_prompt(story, scene, style_override)
            
            # V√©rification du cache
            cache_key = self._get_cache_key(image_prompt)
            if cache_key in self._image_cache:
                print(f"Image trouv√©e en cache pour la sc√®ne {scene.scene_number}")
                return self._image_cache[cache_key]
            
            # G√©n√©ration de l'image
            image_path = await self._generate_image(image_prompt, story.story_id, scene.scene_number)
            
            if image_path:
                # Mise √† jour du cache
                self._image_cache[cache_key] = image_path
                
                # Limitation de la taille du cache
                if len(self._image_cache) > self._cache_max_size:
                    oldest_key = next(iter(self._image_cache))
                    del self._image_cache[oldest_key]
                
                # Mise √† jour de la sc√®ne
                scene.image_url = image_path
                scene.image_prompt = image_prompt
                
                return image_path
            
            return None
            
        except Exception as e:
            print(f"Erreur g√©n√©ration image pour sc√®ne {scene.scene_number}: {str(e)}")
            return None
    
    def _build_image_prompt(self, story: Story, scene: Scene, style_override: Optional[str] = None) -> str:
        """
        Construit un prompt visuel √† partir du contexte narratif
        
        Args:
            story: Histoire pour le contexte
            scene: Sc√®ne √† illustrer
            style_override: Style personnalis√© optionnel
            
        Returns:
            str: Prompt visuel optimis√©
        """
        # Style de base selon le genre ou override
        if style_override:
            style = style_override
        else:
            style = self._genre_styles[story.genre]["base_style"]
        
        # Extraction des √©l√©ments visuels du texte narratif
        visual_elements = self._extract_visual_elements(scene.narrative_text)
        
        # Construction du prompt principal
        main_prompt = f"{visual_elements}, {style}"
        
        # Ajout d'√©l√©ments de genre sp√©cifiques
        genre_elements = self._genre_styles[story.genre]["elements"]
        full_prompt = f"{main_prompt}, {genre_elements}"
        
        # Ajout des qualificatifs de qualit√©
        quality_terms = "highly detailed, professional artwork, cinematic lighting, masterpiece"
        final_prompt = f"{full_prompt}, {quality_terms}"
        
        return final_prompt
    
    def _extract_visual_elements(self, narrative_text: str) -> str:
        """
        Extrait les √©l√©ments visuels descriptifs du texte narratif
        
        Args:
            narrative_text: Texte de la sc√®ne
            
        Returns:
            str: √âl√©ments visuels extraits
        """
        # V√©rification que narrative_text n'est pas None ou vide
        if not narrative_text:
            return "atmospheric scene, detailed environment"
        
        # Simplification pour l'instant - extraction basique
        # TODO: Impl√©menter NLP pour extraction sophistiqu√©e
        
        # Mots-cl√©s visuels communs √† rechercher
        visual_keywords = {
            'forest': 'mystical forest',
            'for√™t': 'mystical forest',
            'castle': 'ancient castle',
            'ch√¢teau': 'ancient castle',
            'space': 'cosmic space scene',
            'espace': 'cosmic space scene',
            'city': 'urban cityscape',
            'ville': 'urban cityscape',
            'mountain': 'majestic mountains',
            'montagne': 'majestic mountains',
            'ocean': 'vast ocean',
            'oc√©an': 'vast ocean',
            'house': 'mysterious house',
            'maison': 'mysterious house',
            'room': 'atmospheric interior room',
            'pi√®ce': 'atmospheric interior room',
            'chambre': 'atmospheric interior room',
            'character': 'dramatic character portrait',
            'personnage': 'dramatic character portrait',
            'creature': 'fantastical creature',
            'cr√©ature': 'fantastical creature',
            'magic': 'magical effects',
            'magie': 'magical effects',
            'magique': 'magical effects',
            'technology': 'futuristic technology',
            'technologie': 'futuristic technology',
            'darkness': 'dark atmospheric scene',
            'obscurit√©': 'dark atmospheric scene',
            'sombre': 'dark atmospheric scene',
            'light': 'dramatic lighting',
            'lumi√®re': 'dramatic lighting'
        }
        
        # Recherche de mots-cl√©s dans le texte
        found_elements = []
        text_lower = narrative_text.lower()
        
        for keyword, visual in visual_keywords.items():
            if keyword in text_lower:
                found_elements.append(visual)
        
        # Si aucun √©l√©ment trouv√©, utiliser un prompt g√©n√©rique
        if not found_elements:
            found_elements = ["atmospheric scene", "detailed environment"]
        
        return ", ".join(found_elements[:3])  # Limiter √† 3 √©l√©ments principaux
    
    async def _generate_image(self, prompt: str, story_id: str, scene_number: int) -> Optional[str]:
        """
        G√©n√®re une image √† partir d'un prompt
        
        Args:
            prompt: Prompt visuel
            story_id: ID de l'histoire
            scene_number: Num√©ro de la sc√®ne
            
        Returns:
            Optional[str]: Chemin vers l'image g√©n√©r√©e
        """
        if not self._model_loaded:
            await self.initialize_model()
        
        if not DIFFUSERS_AVAILABLE or self._pipeline is None:
            return self._create_placeholder_image(story_id, scene_number)
        
        try:
            # G√©n√©ration avec seed pour reproductibilit√©
            generator = torch.Generator(device=self.device)
            generator.manual_seed(hash(f"{story_id}_{scene_number}") % 2**32)
            
            # Prompt n√©gatif pour am√©liorer la qualit√©
            negative_prompt = self.negative_prompts.get("default", "blurry, low quality, distorted")
            
            print(f"G√©n√©ration d'image pour sc√®ne {scene_number}...")
            print(f"Prompt: {prompt[:100]}...")
            start_time = time.time()
            
            # G√©n√©ration selon documentation officielle SDXL-Turbo:
            # - num_inference_steps=2-4 (balance qualit√©/vitesse)
            # - guidance_scale=0.0 (no guidance)
            # - R√©solution 512x512 (native pour SDXL-Turbo)
            try:
                result = self._pipeline(
                    prompt=prompt,
                    num_inference_steps=2,  # 2 steps pour meilleure qualit√©
                    guidance_scale=0.0,
                    width=512,  # R√©solution native SDXL-Turbo
                    height=512,
                    generator=generator,
                    output_type="pil"  # Forcer output PIL
                )
            except Exception as gen_error:
                print(f"Erreur lors de la g√©n√©ration avec param√®tres complets: {gen_error}")
                import traceback
                traceback.print_exc()
                # Essai avec le strict minimum
                try:
                    result = self._pipeline(prompt)
                except Exception as simple_error:
                    print(f"Erreur aussi avec param√®tres minimaux: {simple_error}")
                    raise  # Relancer pour le catch externe
            
            generation_time = time.time() - start_time
            print(f"Image g√©n√©r√©e en {generation_time:.2f}s")
            
            # Sauvegarde de l'image
            image = result.images[0]
            
            # V√©rifier s'il y a des valeurs invalides
            import numpy as np
            img_array = np.array(image)
            
            if np.isnan(img_array).any() or img_array.max() == 0:
                print("‚ö†Ô∏è Image invalide d√©tect√©e (NaN ou valeurs nulles). G√©n√©ration d'un placeholder...")
                return self._create_placeholder_image(story_id, scene_number)
            
            image_path = self._save_image(image, story_id, scene_number)
            
            return image_path
            
        except Exception as e:
            print(f"Erreur lors de la g√©n√©ration d'image: {str(e)}")
            return self._create_placeholder_image(story_id, scene_number)
    
    def _save_image(self, image: Image.Image, story_id: str, scene_number: int) -> str:
        """
        Sauvegarde une image g√©n√©r√©e
        
        Args:
            image: Image PIL √† sauvegarder
            story_id: ID de l'histoire
            scene_number: Num√©ro de la sc√®ne
            
        Returns:
            str: Chemin relatif vers l'image sauvegard√©e (format: {story_id}/{filename})
        """
        # Cr√©ation du r√©pertoire sp√©cifique √† l'histoire
        story_images_dir = os.path.join(self.images_path, story_id)
        os.makedirs(story_images_dir, exist_ok=True)
        
        # Nom de fichier avec timestamp pour unicit√©
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"scene_{scene_number:03d}_{timestamp}.png"
        image_path = os.path.join(story_images_dir, filename)
        
        # Sauvegarde avec optimisation
        image.save(image_path, "PNG", optimize=True, quality=85)
        
        # Retourner le chemin relatif pour l'API (story_id/filename)
        return f"{story_id}/{filename}"
    
    def _create_placeholder_image(self, story_id: str, scene_number: int) -> str:
        """
        Cr√©e une image placeholder en mode d√©grad√©
        
        Args:
            story_id: ID de l'histoire
            scene_number: Num√©ro de la sc√®ne
            
        Returns:
            str: Chemin vers l'image placeholder
        """
        try:
            # Cr√©ation d'une image simple avec PIL
            from PIL import Image, ImageDraw, ImageFont
            
            image = Image.new('RGB', (512, 512), color=(70, 70, 100))
            draw = ImageDraw.Draw(image)
            
            # Texte placeholder
            text = f"Scene {scene_number}\n[Image Generation\nUnavailable]"
            
            # Tentative d'utiliser une police par d√©faut
            try:
                font = ImageFont.truetype("arial.ttf", 24)
            except:
                font = ImageFont.load_default()
            
            # Centrage du texte
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            x = (512 - text_width) // 2
            y = (512 - text_height) // 2
            
            draw.text((x, y), text, fill=(200, 200, 200), font=font, align='center')
            
            # Sauvegarde
            return self._save_image(image, story_id, scene_number)
            
        except Exception as e:
            print(f"Erreur cr√©ation placeholder: {str(e)}")
            return f"placeholder_scene_{scene_number}.png"
    
    def _get_cache_key(self, prompt: str) -> str:
        """
        G√©n√®re une cl√© de cache pour un prompt
        
        Args:
            prompt: Prompt √† hasher
            
        Returns:
            str: Cl√© de cache unique
        """
        return hashlib.md5(prompt.encode()).hexdigest()
    
    def _initialize_genre_styles(self) -> Dict[StoryGenre, Dict[str, str]]:
        """
        Initialise les styles visuels par genre
        
        Returns:
            Dict: Styles structur√©s par genre
        """
        return {
            StoryGenre.FANTASY: {
                "base_style": "fantasy art, magical realism, ethereal atmosphere",
                "elements": "enchanted forest, mystical creatures, magical effects, medieval architecture, glowing lights, fantasy landscape"
            },
            StoryGenre.SCIENCE_FICTION: {
                "base_style": "sci-fi art, futuristic, cyberpunk aesthetic, digital art",
                "elements": "spaceships, alien worlds, futuristic technology, neon lights, holographic displays, space stations"
            },
            StoryGenre.HORROR: {
                "base_style": "dark horror art, gothic atmosphere, ominous lighting",
                "elements": "haunted house, creepy shadows, fog, dark corridors, mysterious figures, eerie atmosphere"
            },
            StoryGenre.MYSTERY: {
                "base_style": "noir mystery art, detective aesthetic, moody lighting",
                "elements": "urban setting, rain, shadows, investigation scene, dramatic lighting, film noir style"
            },
            StoryGenre.ADVENTURE: {
                "base_style": "adventure art, dynamic composition, epic landscape",
                "elements": "mountain peaks, treasure maps, ancient ruins, jungle exploration, heroic poses, dramatic skies"
            },
            StoryGenre.ROMANCE: {
                "base_style": "romantic art, soft lighting, warm colors, emotional atmosphere",
                "elements": "elegant settings, soft focus, golden hour lighting, intimate scenes, beautiful landscapes, dreamy atmosphere"
            }
        }
    
    def get_model_status(self) -> Dict[str, any]:
        """
        Retourne l'√©tat actuel du mod√®le d'images
        
        Returns:
            Dict: Informations sur l'√©tat du mod√®le
        """
        return {
            "model_loaded": self._model_loaded,
            "model_name": self.model_name,
            "device": self.device,
            "diffusers_available": DIFFUSERS_AVAILABLE,
            "cache_size": len(self._image_cache),
            "images_path": self.images_path
        }
    
    def clear_cache(self):
        """Nettoie le cache d'images"""
        self._image_cache.clear()
        print("Cache d'images nettoy√©")
    
    async def generate_custom_image(self, prompt: str, style: str = "default") -> Optional[str]:
        """
        G√©n√®re une image personnalis√©e avec prompt libre
        
        Args:
            prompt: Prompt libre pour la g√©n√©ration
            style: Style √† appliquer
            
        Returns:
            Optional[str]: Chemin vers l'image g√©n√©r√©e
        """
        custom_prompt = f"{prompt}, {self._genre_styles[StoryGenre.FANTASY]['base_style']}"
        return await self._generate_image(custom_prompt, "custom", 0)